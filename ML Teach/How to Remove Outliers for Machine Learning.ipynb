{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Remove Outliers for Machine Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference https://machinelearningmastery.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=50.049 stdv=4.994\n"
     ]
    }
   ],
   "source": [
    "# generate gaussian data\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import matplotlib.pyplot as plt\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations center on 50\n",
    "data = 5 * randn(10000) + 50\n",
    "# summarize\n",
    "print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Deviation Method\n",
    "\n",
    "If we know that the distribution of is  Gaussian or Gaussian-like, we can use the standard deviation of the sample as a cut-off for identifying outliers.\n",
    "\n",
    "The Gaussian distribution has the property that the standard deviation from the mean can be used to reliably summarize the percentage of values in the sample.\n",
    "\n",
    "For example, within one standard deviation of the mean will cover 68% of the data.\n",
    "\n",
    "So, if the mean is 50 and the standard deviation is 5, as in the test dataset above, then all data in the sample between 45 and 55 will account for about 68% of the data sample. We can cover more of the data sample if we expand the range as follows:\n",
    "\n",
    "1 Standard Deviation from the Mean: 68%\n",
    "2 Standard Deviations from the Mean: 95%\n",
    "3 Standard Deviations from the Mean: 99.7%\n",
    "\n",
    "A value that falls outside of 3 standard deviations is part of the distribution, but it is an unlikely or rare event at approximately 1 in 370 samples.\n",
    "\n",
    "Three standard deviations from the mean is a common cut-off in practice for identifying outliers in a Gaussian or Gaussian-like distribution. For smaller samples of data, perhaps a value of 2 standard deviations (95%) can be used, and for larger samples, perhaps a value of 4 standard deviations (99.9%) can be used.\n",
    "\n",
    "Given mu and sigma, a simple way to identify outliers is to compute a z-score for every xi, which is defined as the number of standard deviations away xi is from the mean […] Data values that have a z-score sigma greater than a threshold, for example, of three, are declared to be outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified outliers: 29\n",
      "Non-outlier observations: 9971\n"
     ]
    }
   ],
   "source": [
    "# identify outliers with standard deviation\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# calculate summary statistics\n",
    "data_mean, data_std = mean(data), std(data)\n",
    "# identify outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have only talked about univariate data with a Gaussian distribution, e.g. a single variable. You can use the same approach if you have multivariate data, e.g. data with multiple variables, each with a different Gaussian distribution.\n",
    "\n",
    "You can imagine bounds in two dimensions that would define an ellipse if you have two variables. Observations that fall outside of the ellipse would be considered outliers. In three dimensions, this would be an ellipsoid, and so on into higher dimensions.\n",
    "\n",
    "Alternately, if you knew more about the domain, perhaps an outlier may be identified by exceeding the limits on one or a subset of the data dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interquartile Range Method\n",
    "\n",
    "Not all data is normal or normal enough to treat it as being drawn from a Gaussian distribution.\n",
    "note once could try to use normaliation algorithms to make data normal, thats a topic for another time.\n",
    "\n",
    "If the data is not normal distribution A good statistic for summarizing a non-Gaussian distribution sample of data is the Interquartile Range, or IQR for short.\n",
    "\n",
    "The IQR is calculated as the difference between the 75th and the 25th percentiles of the data and defines the box in a box and whisker plot.\n",
    "\n",
    "Remember that percentiles can be calculated by sorting the observations and selecting values at specific indices. The 50th percentile is the middle value, or the average of the two middle values for an even number of examples. If we had 10,000 samples, then the 50th percentile would be the average of the 5000th and 5001st values.\n",
    "\n",
    "We refer to the percentiles as quartiles (“quart” meaning 4) because the data is divided into four groups via the 25th, 50th and 75th values.\n",
    "\n",
    "The IQR defines the middle 50% of the data, or the body of the data.\n",
    "\n",
    "Statistics-based outlier detection techniques assume that the normal data points would appear in high probability regions of a stochastic(random probability) model, while outliers would occur in the low probability regions of a stochastic model.\n",
    "\n",
    "— Page 12, Data Cleaning, 2019.\n",
    "\n",
    "The IQR can be used to identify outliers by defining limits on the sample values that are a factor k of the IQR below the 25th percentile or above the 75th percentile. \n",
    "\n",
    "<font color='red'>\n",
    "The common value for the factor k is the value 1.5. A factor k of 3 or more can be used to identify values that are extreme outliers or “far outs” when described in the context of box and whisker plots.\n",
    "</font> \n",
    "\n",
    "On a box and whisker plot, these limits are drawn as fences on the whiskers (or the lines) that are drawn from the box. Values that fall outside of these values are drawn as dots.\n",
    "\n",
    "We can calculate the percentiles of a dataset using the percentile() NumPy function that takes the dataset and specification of the desired percentile. The IQR can then be calculated as the difference between the 75th and 25th percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: 25th=53.000, 75th=56.000, IQR=3.000\n",
      "Identified outliers: 133\n",
      "Non-outlier observations: 9867\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# identify outliers with interquartile range\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile\n",
    "import numpy as np\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "#data = 5 * randn(10000) + 50\n",
    "data = np.random.poisson(5, 100000) + 50\n",
    "\n",
    "# calculate interquartile range\n",
    "q25, q75 = percentile(data, 25), percentile(data, 75)\n",
    "iqr = q75 - q25\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))\n",
    "plt.hist(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The approach can be used for multivariate data by calculating the limits on each variable in the dataset in turn, and taking outliers as observations that fall outside of the rectangle or hyper-rectangle.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Automatic Outlier Detection</h2>\n",
    "<p>In machine learning, an approach to tackling the problem of outlier detection is <a href=\"https://en.wikipedia.org/wiki/One-class_classification\">one-class classification</a>.</p>\n",
    "<p>One-Class Classification, or OCC for short, involves fitting a model on the “<em>normal</em>” data and predicting whether new data is normal or an outlier/anomaly.</p>\n",
    "<blockquote><p>A one-class classifier aims at capturing characteristics of training instances, in order to be able to distinguish between them and potential outliers to appear.</p></blockquote>\n",
    "<p>— Page 139, <a href=\"https://amzn.to/307Xlva\">Learning from Imbalanced Data Sets</a>, 2018.</p>\n",
    "<p>A one-class classifier is fit on a training dataset that only has examples from the normal class. Once prepared, the model is used to classify new examples as either normal or not-normal, i.e. outliers or anomalies.</p>\n",
    "<p>A simple approach to identifying outliers is to locate those examples that are far from the other examples in the feature space.</p>\n",
    "<p>This can work well for feature spaces with low dimensionality (few features), although it can become less reliable as the number of features is increased, referred to as the curse of dimensionality.</p>\n",
    "<p>The local outlier factor, or LOF for short, is a technique that attempts to harness the idea of nearest neighbors for outlier detection. Each example is assigned a scoring of how isolated or how likely it is to be outliers based on the size of its local neighborhood. Those examples with the largest score are more likely to be outliers.</p>\n",
    "<blockquote><p>We introduce a local outlier (LOF) for each object in the dataset, indicating its degree of outlier-ness.</p></blockquote>\n",
    "<p>— <a href=\"https://dl.acm.org/citation.cfm?id=335388\">LOF: Identifying Density-based Local Outliers</a>, 2000.</p>\n",
    "<p>The scikit-learn library provides an implementation of this approach in the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html\">LocalOutlierFactor class</a>.</p>\n",
    "<p>We can demonstrate the LocalOutlierFactor method on a predictive modelling dataset.</p>\n",
    "<p>We will use the Boston housing regression problem that has 13 inputs and one numerical target and requires learning the relationship between suburb characteristics and house prices.</p>\n",
    "<p>The dataset can be downloaded from here:</p>\n",
    "<ul>\n",
    "<li><a href=\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv\">Boston Housing Dataset (housing.csv)</a></li>\n",
    "<li><a href=\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.names\">Boston Housing Dataset Details (housing.names)</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "\n",
       "       11    12    13  \n",
       "0  396.90  4.98  24.0  \n",
       "1  396.90  9.14  21.6  \n",
       "2  392.83  4.03  34.7  \n",
       "3  394.63  2.94  33.4  \n",
       "4  396.90  5.33  36.2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model on the raw dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "df = read_csv(url, header=None)\n",
    "\n",
    "# retrieve the array\n",
    "data = df.values\n",
    "\n",
    "#check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.417\n"
     ]
    }
   ],
   "source": [
    "# split into inpiut and output elements\n",
    "# x = all rows , all columns not incuding last, \n",
    "# y = all rows, only last colum \n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next, we can try removing outliers from the training dataset.</p>\n",
    "<p>The expectation is that the outliers are causing the linear regression model to learn a bias or skewed understanding of the problem, and that removing these outliers from the training set will allow a more effective model to be learned.</p>\n",
    "<p>We can achieve this by defining the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html\">LocalOutlierFactor</a> model and using it to make a prediction on the training dataset, marking each row in the training dataset as normal (1) or an outlier (-1). We will use the default hyperparameters for the outlier detection model, although it is a good idea to tune the configuration to the specifics of your dataset.</p><!-- Urvanov Syntax Highlighter v2.8.12 -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify outliers in the training dataset\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "lof = LocalOutlierFactor() # there are parameters we can play with here , default is used for this example \n",
    "yhat = lof.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True, False,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True, False,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask generated by LOF is used to filter data \n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 13) (305,)\n",
      "MAE: 3.356\n"
     ]
    }
   ],
   "source": [
    "# summarize the shape of the updated training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
